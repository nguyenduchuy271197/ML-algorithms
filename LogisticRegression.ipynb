{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LogisticRegression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9+qhFmUuD4L4zFSIEOxXb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"92EK83XwlR3T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597121650153,"user_tz":-420,"elapsed":1012,"user":{"displayName":"Huy Nguyễn Đức","photoUrl":"","userId":"11770940485160332546"}}},"source":["import numpy as np\n","#X: mxn, y:mx1, w:nx1\n","class LogisticRegression:\n","  def __init__(self, learning_rate = 1e-3, n_iterations = 10):\n","    self.learning_rate = learning_rate\n","    self.n_iterations = n_iterations\n","    self.w = None\n","  def sigmoid(self, x):\n","    return 1/(1+np.exp(-x))\n","\n","  def y_hat(self, X):\n","    return self.sigmoid(np.dot(X,self.w))    \n","\n","  def loss(self, yhat, y):\n","    J = y*np.log(yhat) + (1-y)*np.log(1-yhat)\n","    return np.mean(J)\n","\n","  def gradient_descent(self, X, yhat, y):\n","    dw = (1 / self.m) * np.dot(X.T, (yhat - y))\n","    self.w -= self.learning_rate*dw\n","    return self.w\n","\n","  def fit(self,X,y):\n","    y = y.reshape(-1,1)\n","    ones_arr = np.ones((X.shape[0], 1))\n","    X = np.append(X, ones_arr, axis = 1)\n","    self.m, self.n = X.shape\n","    # initial weight\n","    self.w = np.zeros((self.n, 1))\n","    # Training phase\n","    for i in range(self.n_iterations):\n","      # yhat\n","      yhat = self.y_hat(X)\n","      # loss\n","      J = self.loss(yhat, y)\n","      if i%(self.n_iterations//10) == 0:\n","        print(f'Loss at iteration {i+1} is {J}')\n","        \n","      # Gradient descent\n","      self.w = self.gradient_descent(X, yhat, y)\n","\n","  def predict(self,X):\n","    ones_arr = np.ones((X.shape[0], 1))\n","    X = np.append(X, ones_arr, axis = 1)\n","    y_predict = self.y_hat(X)\n","    y_predict_class = [1 if j >= 0.5 else 0 for j in y_predict]\n","    return y_predict_class\n","  \n","  def accuracy(self, yhat, y):\n","    return np.sum(yhat == y)/len(yhat)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHCwEUZZmUCT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597121652197,"user_tz":-420,"elapsed":1000,"user":{"displayName":"Huy Nguyễn Đức","photoUrl":"","userId":"11770940485160332546"}},"outputId":"29b698f7-499c-4aa8-ed6e-133f7673ef2a"},"source":["# Load dataset\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","bc = load_breast_cancer()\n","X,y = bc.data, bc.target\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","\n","logistic_regression = LogisticRegression(learning_rate = 0.00001, n_iterations= 1000)\n","logistic_regression.fit(X_train, y_train)\n","predictions = logistic_regression.predict(X_val)\n","acc = logistic_regression.accuracy(predictions, y_val)\n","acc"],"execution_count":56,"outputs":[{"output_type":"stream","text":["Loss at iteration 1 is -0.6931471805599453\n","Loss at iteration 101 is -0.4584087546728591\n","Loss at iteration 201 is -0.355176736183702\n","Loss at iteration 301 is -0.32461390132401113\n","Loss at iteration 401 is -0.3032509775032446\n","Loss at iteration 501 is -0.2877120346760734\n","Loss at iteration 601 is -0.27603641087046776\n","Loss at iteration 701 is -0.2669627200994013\n","Loss at iteration 801 is -0.25969321731720313\n","Loss at iteration 901 is -0.25372127863885907\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9122807017543859"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"tdy35UVpvJP0","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}